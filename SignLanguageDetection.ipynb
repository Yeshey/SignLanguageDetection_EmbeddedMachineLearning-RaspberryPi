{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SignLanguageDetection_EmbeddedMachineLearning-RaspberryPi\n",
    "\n",
    "Project to deploy a Machine Learning Model on a Rasberry Pi.  \n",
    "Training a model to identify american sign language letters in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Time setup  \n",
    "- You're expected to have [install](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tf-install)ed [tensorflow in your PC](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tf-install), check the References in the bottom for notes.\n",
    "- After that, in your conda environment, there are a several dependencies you must install:\n",
    "  - if you created your connda environment with `conda create -n signLanguageDetector pip python=3.9` for example.\n",
    "  - run `conda activate signLanguageDetector`\n",
    "  - `pip install wget hazm pandas` and other libraries that appear that might be needed.\n",
    "- To download the dataset and the pre-trained-model run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget \n",
    "import zipfile\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "print(\"Running first time setup...\")\n",
    "\n",
    "# check folders\n",
    "ckckfldrs = os.listdir(\"./TensorFlow/workspace/training_demo/\")\n",
    "\n",
    "if all( i != \"images\" for i in ckckfldrs):\n",
    "    os.mkdir(\"./TensorFlow/workspace/training_demo/images\")\n",
    "    # Downloading database\n",
    "    print(\"thanks to https://public.roboflow.com/object-detection/american-sign-language-letters/1 for dataset\")\n",
    "    print(\"Downloading Dataset to ./TensorFlow/workspace/training_demo/images/...\")\n",
    "    url = 'https://public.roboflow.com/ds/wdx82NVcss?key=lyVASY8xq4'\n",
    "    path = './TensorFlow/workspace/training_demo/images/'\n",
    "    wget.download(url,out = path)\n",
    "\n",
    "    print(\"\\nUnzipping...\")\n",
    "    zipPath = os.listdir(\"./TensorFlow/workspace/training_demo/images/\")\n",
    "    zipPath = \"./TensorFlow/workspace/training_demo/images/\" + str(zipPath[0])\n",
    "    print(zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./TensorFlow/workspace/training_demo/images/\")\n",
    "\n",
    "    for item in os.listdir(\"./TensorFlow/workspace/training_demo/images/\"): # loop through items in dir\n",
    "        if item.endswith(\".zip\"): # check for \".zip\" extension\n",
    "            os.remove(\"./TensorFlow/workspace/training_demo/images/\"+ item)\n",
    "else:\n",
    "    print(\"images folder already exists\")\n",
    "\n",
    "if all( i != \"pre-trained-models\" for i in ckckfldrs):\n",
    "    os.mkdir(\"./TensorFlow/workspace/training_demo/pre-trained-models\")\n",
    "    # Downloading Pre-trained model\n",
    "    print(\"using SSD ResNet50 V1 FPN 640x640 pre-trained model from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\")\n",
    "    print(\"Downloading pre-trained model to ./TensorFlow/workspace/training_demo/pre-trained-models/..\")\n",
    "    url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "    path = './TensorFlow/workspace/training_demo/pre-trained-models/'\n",
    "    wget.download(url,out = path)\n",
    "\n",
    "    print(\"\\nUnzipping...\")\n",
    "    zipPath = os.listdir(\"./TensorFlow/workspace/training_demo/pre-trained-models/\")\n",
    "    zipPath = \"./TensorFlow/workspace/training_demo/pre-trained-models/\" + str(zipPath[0])\n",
    "    tar = tarfile.open(zipPath, \"r:gz\")\n",
    "    tar.extractall('./TensorFlow/workspace/training_demo/pre-trained-models/')\n",
    "    tar.close()\n",
    "\n",
    "    for item in os.listdir(\"./TensorFlow/workspace/training_demo/pre-trained-models/\"): # loop through items in dir\n",
    "        if item.endswith(\".tar.gz\"): # check for \".zip\" extension\n",
    "            os.remove(\"./TensorFlow/workspace/training_demo/pre-trained-models/\"+ item)\n",
    "else:\n",
    "    print(\"pre-trained-models folder already exists\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Generate .record files from labeled dataset](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records)\n",
    "(if you're using the same dataset as me, they're already generated!)  \n",
    "Something like:\n",
    "\n",
    "```bash\n",
    "# Create train data:\n",
    "python ./TensorFlow/scripts/preprocessing/generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/train -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/train.record\n",
    "\n",
    "# Create test data:\n",
    "python ./TensorFlow/scripts/preprocessing/generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/test -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/test.record\n",
    "\n",
    "# For example\n",
    "# python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/train -l C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/train.record\n",
    "# python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/test -l C:/Users/sglvladi/Documents/Tensorflow2/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/test.record\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if all( i != \"model_main_tf2.py\" for i in os.listdir(\".\")):\n",
    "    os.chdir('./TensorFlow/workspace/training_demo/') # Change the working directory\n",
    "    print(f\"working directory now: {os.getcwd()}\")\n",
    "%run -i 'model_main_tf2.py' --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config\n",
    "os.chdir('../../../')\n",
    "print(f\"working directory now: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Monitor Training Job Progress using TensorBoard](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#tensorboard-sec)\n",
    "1. While the model trains, you can \n",
    "   1. cd into the training_demo folder\n",
    "   2. run `tensorboard --logdir=models/my_ssd_resnet50_v1_fpn` \n",
    "   3. access http://localhost:6006/ in your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Evaluating the Model](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#evaluating-the-model-optional)\n",
    "1. After the model has been trained, you can see how good it does by:\n",
    "   1. cd into the training_demo folder\n",
    "   2. run `python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config --checkpoint_dir=models/my_ssd_resnet50_v1_fpn`\n",
    "   3. access http://localhost:6006/ in your browser\n",
    "   4. seing in the images section, the eval:side_by_side images to see how good it is detecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exporting the Trained Model](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if all( i != \"exporter_main_v2.py\" for i in os.listdir(\".\")):\n",
    "    os.chdir('./TensorFlow/workspace/training_demo/') # Change the working directory\n",
    "    print(f\"working directory now: {os.getcwd()}\")\n",
    "%run -i './exporter_main_v2.py' --input_type image_tensor --pipeline_config_path ./models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_resnet50_v1_fpn/ --output_directory ./exported-models/my_model\n",
    "os.chdir('../../../')\n",
    "print(f\"working directory now: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Detect Objects Using Your Webcam](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/object_detection_camera.html#detect-objects-using-your-webcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), 'TensorFlow/workspace/training_demo/')\n",
    "MODELS_DIR = os.path.join(DATA_DIR, 'exported-models')\n",
    "MODEL_NAME = 'my_model_american_alphabet_sign_language'\n",
    "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
    "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load label map data (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = os.path.join(os.getcwd(), 'TensorFlow/workspace/training_demo/annotations/label_map.pbtxt')\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qt: Session management error: Could not open network socket\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret, image_np = cap.read()\n",
    "\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'][0].numpy(),\n",
    "          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "          detections['detection_scores'][0].numpy(),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    # Display output\n",
    "    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Training the model\n",
    "1. Following [*Training Custom Object Detector*](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html) tutorial\n",
    "     - [TensorFlow Installation](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tf-install) Notes:\n",
    "       - With Anaconda installed, use `conda info --envs` to see created environments\n",
    "       - Before working on the project, do `conda activate signLanguageDetector` to activate the environment every time\n",
    "       - Install cuda and cudnn tu use GPU on manjaro with `sudo pacman -S cuda cudnn`\n",
    "       - For Object detection API, added the [TensorFlow Models repository](https://github.com/tensorflow/models) as a git submodule with the command `git submodule add https://github.com/tensorflow/models ./TensorFlow/models/`\n",
    "       - To test if everything worked out in the installation you can run `python TensorFlow/models/research/object_detection/builders/model_builder_tf2_test.py`\n",
    "      - Dataset from roboflow.com: [American Sign Language Letters Dataset](https://public.roboflow.com/object-detection/american-sign-language-letters/1)\n",
    "      - Had to do [this](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md#python-package-installation) before training to fix an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "832373f34c5392a1ac8810e042c819613272440a316383854975927ea4f31b34"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('signLanguageDetector')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
