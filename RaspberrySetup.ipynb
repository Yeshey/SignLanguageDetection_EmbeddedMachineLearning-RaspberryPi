{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspberry Pi Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "1. Its advised to create a contained environment to install all dependencies as explained [here](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#step-1b-download-this-repository-and-create-virtual-environment)\n",
    "   1. `cd ~`\n",
    "   2. `sudo pip3 install virtualenv`\n",
    "   3. `python3 -m venv tflite1-env`\n",
    "   4. `source ~/tflite1-env/bin/activate`\n",
    "   5. Note you'll have to run the above command every time you open a new terminal to work on this project now, you can add it to `~/.bashrc` so its executed automatically every time you open a terminal with this command:\n",
    "      `echo 'source ~/tflite1-env/bin/activate' >> ~/.bashrc`\n",
    "   6. If in a new terminal you see (tflite1-env) instead of (base) behind the prompt, it's working\n",
    "2. Following [*TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi*](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi)\n",
    "   - For the time being, installing picamera2 is a hassel due to the transition from the legacy camera to the libcamera stack on the raspberry  \n",
    "     To install it, we need to build several dependencies, these are in `./RaspberryPi/picamera2Setup/` in this repo  \n",
    "     [following these instructions](https://www.raspberrypi.com/news/using-the-picamera2-library-with-tensorflow-lite/), we have to:\n",
    "     1. Install dependencies:\n",
    "        ```bash\n",
    "          sudo apt update\n",
    "          sudo apt install -y libboost-dev\n",
    "          sudo apt install -y libgnutls28-dev openssl libtiff5-dev\n",
    "          sudo apt install -y qtbase5-dev libqt5core5a libqt5gui5 libqt5widgets5\n",
    "          sudo apt install -y meson\n",
    "          sudo pip3 install pyyaml ply\n",
    "          sudo pip3 install --upgrade meson\n",
    "          sudo apt install -y libglib2.0-dev libgstreamer-plugins-base1.0-dev\n",
    "          sudo pip3 install pyopengl\n",
    "          sudo apt install python3-pyqt5\n",
    "          sudo pip3 install opencv-python==4.4.0.46\n",
    "          sudo apt install -y libatlas-base-dev\n",
    "          pip3 install numpy\n",
    "          sudo apt install build-essentials\n",
    "          sudo apt install git\n",
    "          sudo apt install python3-pip\n",
    "          pip3 install tflite-runtime\n",
    "          pip3 install opencv-python==4.4.0.46\n",
    "          pip3 install pillow\n",
    "          sudo pip3 install numpy --upgrade\n",
    "\n",
    "          pip3 install pyqt5\n",
    "\n",
    "          sudo apt-get install libyaml-dev\n",
    "          sudo apt-get install libudev-dev\n",
    "          sudo apt install -y cmake\n",
    "          sudo apt-get install python-jinja2\n",
    "          sudo apt-get install python-ply\n",
    "          sudo pip3 install pyyaml\n",
    "          sudo apt-get install python3-sphinx\n",
    "          sudo apt-get install qttools5-dev-tools\n",
    "          pip3 install python-prctl==1.6.1\n",
    "          pip3 install simplejpeg\n",
    "          pip3 install piexif\n",
    "          pip3 install pidng\n",
    "          pip3 install PyOpenGL\n",
    "        ```\n",
    "     2. you might have to [increase the swap](https://stackoverflow.com/questions/30887143/make-j-8-g-internal-compiler-error-killed-program-cc1plus) to build it successfully too. Check with `top` that you have not much less than 2Gb with RAM and SWAP combined\n",
    "     3. Building Picamera2 library:\n",
    "          1. Install all the dependencies in */RaspberryPi/picamera2Setup/picamera2/README.rst*\n",
    "               - Something like (the command is likely to be depracated rapidaly)  \n",
    "                 `sudo apt-get install -y ninja-build pkg-config libgnutls28-dev openssl libgnutls28-dev openssl libboost-dev libudev-dev python3-sphinx doxygen graphviz texlive-latex-extra libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libevent-dev qtbase5-dev libqt5core5a libqt5gui5 libqt5widgets5 qttools5-dev-tools libtiff-dev liblttng-ust-dev python3-jinja2 lttng-tools libevent-dev libexif-dev libjpeg-dev`\n",
    "          2. `cd /RaspberryPi/picamera2Setup/libcamera`\n",
    "          3. `meson build --buildtype=release -Dpipelines=raspberrypi -Dipas=raspberrypi -Dv4l2=true -Dgstreamer=enabled -Dtest=false -Dlc-compliance=disabled -Dcam=disabled -Dqcam=enabled -Ddocumentation=disabled -Dpycamera=enabled`\n",
    "          4. `ninja -C build`\n",
    "          5. `sudo ninja -C build install`\n",
    "     4. Building kmsxx library:\n",
    "          1. `cd /RaspberryPi/picamera2Setup/kmsxx`\n",
    "          2. `git submodule update --init`\n",
    "          3. `meson build`\n",
    "          4. `ninja -C build`\n",
    "     5. To make everything run, you will also have to set your `PYTHONPATH` environment variable. For example, we can add it to the `.bashrc` file:  \n",
    "        alter the following line so it points to your dependencies in your system in `/RaspberryPi/picamera2Setup/`\n",
    "        `export PYTHONPATH=/home/pi/repo/RaspberryPi/picamera2Setup/picamera2:/home/pi/repo/RaspberryPi/picamera2Setup/libcamera/build/src/py:/home/pi/repo/RaspberryPi/picamera2Setup/kmsxx/build/py:/home/pi/repo/RaspberryPi/picamera2Setup/python-v4l2`\n",
    "- notes/other links:\n",
    "   - [opencv with raspberry libcamera in C++](https://github.com/Qengineering/Libcamera-OpenCV-RPi-Bullseye-32OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the installation\n",
    "\n",
    "- take a look into `run_Raspberry.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /home/pi/pyVision/tflite1-env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simplejpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/pi/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberrySetup.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Braspberry/home/pi/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberrySetup.ipynb#ch0000003vscode-remote?line=31'>32</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Braspberry/home/pi/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberrySetup.ipynb#ch0000003vscode-remote?line=32'>33</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageFont, ImageDraw\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Braspberry/home/pi/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberrySetup.ipynb#ch0000003vscode-remote?line=34'>35</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpicamera2\u001b[39;00m \u001b[39mimport\u001b[39;00m Picamera2, Preview, MappedArray\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Braspberry/home/pi/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberrySetup.ipynb#ch0000003vscode-remote?line=36'>37</a>\u001b[0m \u001b[39m#normalSize = (640, 480)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Braspberry/home/pi/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberrySetup.ipynb#ch0000003vscode-remote?line=37'>38</a>\u001b[0m \u001b[39m#lowresSize = (320, 240)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Braspberry/home/pi/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberrySetup.ipynb#ch0000003vscode-remote?line=38'>39</a>\u001b[0m normalSize \u001b[39m=\u001b[39m (\u001b[39m1280\u001b[39m, \u001b[39m960\u001b[39m)\n",
      "File \u001b[0;32m~/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberryPi/picamera2Setup/picamera2/picamera2/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpicamera2\u001b[39;00m \u001b[39mimport\u001b[39;00m Picamera2, Preview\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m \u001b[39mimport\u001b[39;00m CompletedRequest, MappedArray\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m YUV420_to_RGB\n",
      "File \u001b[0;32m~/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberryPi/picamera2Setup/picamera2/picamera2/picamera2.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpicamera2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mencoders\u001b[39;00m \u001b[39mimport\u001b[39;00m Encoder\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpicamera2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moutputs\u001b[39;00m \u001b[39mimport\u001b[39;00m FileOutput\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpicamera2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize_logger\n",
      "File \u001b[0;32m~/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberryPi/picamera2Setup/picamera2/picamera2/encoders/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mencoder\u001b[39;00m \u001b[39mimport\u001b[39;00m Encoder\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mh264_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m H264Encoder\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mjpeg_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m JpegEncoder\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmjpeg_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m MJPEGEncoder\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmulti_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiEncoder\n",
      "File \u001b[0;32m~/pyVision/SignLanguageDetection_TenserFlow_RaspberryPi/RaspberryPi/picamera2Setup/picamera2/picamera2/encoders/jpeg_encoder.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msimplejpeg\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpicamera2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mencoders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiEncoder\n\u001b[1;32m      6\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mJpegEncoder\u001b[39;00m(MultiEncoder):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simplejpeg'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "# Copyright (c) 2022 Raspberry Pi Ltd\n",
    "# Author: Alasdair Allan <alasdair@raspberrypi.com>\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "# A TensorFlow Lite example for Picamera2 on Raspberry Pi OS Bullseye\n",
    "#\n",
    "# Install necessary dependences before starting,\n",
    "#\n",
    "# $ sudo apt update\n",
    "# $ sudo apt install build-essentials\n",
    "# $ sudo apt install libatlas-base-dev\n",
    "# $ sudo apt install python3-pip\n",
    "# $ pip3 install tflite-runtime\n",
    "# $ pip3 install opencv-python==4.4.0.46\n",
    "# $ pip3 install pillow\n",
    "# $ pip3 install numpy\n",
    "#\n",
    "# and run from the command line,\n",
    "#\n",
    "# $ python3 real_time_with_labels.py --model mobilenet_v2.tflite --label coco_labels.txt\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFont, ImageDraw\n",
    "\n",
    "from picamera2 import Picamera2, Preview, MappedArray\n",
    "\n",
    "#normalSize = (640, 480)\n",
    "#lowresSize = (320, 240)\n",
    "normalSize = (1280, 960)\n",
    "lowresSize = (640, 480)\n",
    "\n",
    "rectangles = []\n",
    "\n",
    "\n",
    "def ReadLabelFile(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    ret = {}\n",
    "    for i,line in enumerate(lines):\n",
    "        ret[i] = line.strip()\n",
    "    return ret\n",
    "\n",
    "\n",
    "def DrawRectangles(request):\n",
    "    with MappedArray(request, \"main\") as m:\n",
    "        for rect in rectangles:\n",
    "            print(rect)\n",
    "            rect_start = (int(rect[0] * 2) - 5, int(rect[1] * 2) - 5)\n",
    "            rect_end = (int(rect[2] * 2) + 5, int(rect[3] * 2) + 5)\n",
    "            cv2.rectangle(m.array, rect_start, rect_end, (0, 255, 0, 0))\n",
    "            if len(rect) == 5:\n",
    "                text = rect[4]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(m.array, text, (int(rect[0] * 2) + 10, int(rect[1] * 2) + 10), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def InferenceTensorFlow(image, model, output, label=None):\n",
    "    global rectangles\n",
    "\n",
    "    if label:\n",
    "        labels = ReadLabelFile(label)\n",
    "    else:\n",
    "        labels = None\n",
    "\n",
    "    interpreter = tflite.Interpreter(model_path=model, num_threads=4)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "    floating_model = False\n",
    "    if input_details[0]['dtype'] == np.float32:\n",
    "        floating_model = True\n",
    "\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    initial_h, initial_w, channels = rgb.shape\n",
    "\n",
    "    picture = cv2.resize(rgb, (width, height))\n",
    "\n",
    "    input_data = np.expand_dims(picture, axis=0)\n",
    "    if floating_model:\n",
    "        input_data = (np.float32(input_data) - 127.5) / 127.5\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "\n",
    "    # The order seemingly changes from my lite model to the google example model\n",
    "    if (example_model == True):\n",
    "        detected_boxes = interpreter.get_tensor(output_details[0]['index'])\n",
    "        detected_classes = interpreter.get_tensor(output_details[1]['index'])\n",
    "        detected_scores = interpreter.get_tensor(output_details[2]['index'])\n",
    "        num_boxes = interpreter.get_tensor(output_details[3]['index'])\n",
    "    else:\n",
    "        detected_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "        detected_boxes = interpreter.get_tensor(output_details[1]['index'])\n",
    "        num_boxes = interpreter.get_tensor(output_details[2]['index'])\n",
    "        detected_classes = interpreter.get_tensor(output_details[3]['index'])\n",
    "\n",
    "    rectangles = []\n",
    "\n",
    "    for i in range(int(num_boxes)):\n",
    "        top, left, bottom, right = detected_boxes[0][i]\n",
    "        classId = int(detected_classes[0][i])\n",
    "        score = detected_scores[0][i]\n",
    "        if score > 0.02:\n",
    "            xmin = left * initial_w\n",
    "            ymin = bottom * initial_h\n",
    "            xmax = right * initial_w\n",
    "            ymax = top * initial_h\n",
    "            box = [xmin, ymin, xmax, ymax]\n",
    "            rectangles.append(box)\n",
    "            if labels:\n",
    "                print(labels[classId], 'score = ', score)\n",
    "                rectangles[-1].append(labels[classId])\n",
    "            else:\n",
    "                print('score = ', score)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model',default=\"\" ,help='Path of the detection model.', required=True)\n",
    "    parser.add_argument('--label', help='Path of the labels file.')\n",
    "    parser.add_argument('--output', help='File path of the output image.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if (args.output):\n",
    "        output_file = args.output\n",
    "    else:\n",
    "        output_file = 'out.jpg'\n",
    "\n",
    "    if (args.label):\n",
    "        label_file = args.label\n",
    "    else:\n",
    "        label_file = None\n",
    "\n",
    "    picam2 = Picamera2()\n",
    "    picam2.start_preview(Preview.QTGL)\n",
    "    config = picam2.preview_configuration(main={\"size\": normalSize},\n",
    "                                          lores={\"size\": lowresSize, \"format\": \"YUV420\"})\n",
    "    picam2.configure(config)\n",
    "\n",
    "    stride = picam2.stream_configuration(\"lores\")[\"stride\"]\n",
    "    picam2.post_callback = DrawRectangles\n",
    "\n",
    "    picam2.start()\n",
    "\n",
    "    while True:\n",
    "        buffer = picam2.capture_buffer(\"lores\")\n",
    "        grey = buffer[:stride * lowresSize[1]].reshape((lowresSize[1], stride))\n",
    "        result = InferenceTensorFlow(grey, args.model, output_file, label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model = True\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model = False\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
