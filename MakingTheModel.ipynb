{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SignLanguageDetection_EmbeddedMachineLearning-RaspberryPi\n",
    "\n",
    "Project to deploy a Machine Learning Model on a Rasberry Pi.  \n",
    "Training a model to identify american sign language letters in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Time setup  \n",
    "- You're expected to have [install](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tf-install)ed [tensorflow in your PC](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tf-install), check the References in the bottom for notes.\n",
    "- After that, in your conda environment, there are a several dependencies you must install:\n",
    "  - if you created your connda environment with `conda create -n signLanguageDetector pip python=3.9` for example.\n",
    "  - run `conda activate signLanguageDetector`\n",
    "  - `pip install wget hazm pandas` and other libraries that appear that might be needed.\n",
    "- To download the dataset and the pre-trained-model run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget \n",
    "import zipfile\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "print(\"Running first time setup...\")\n",
    "\n",
    "# check folders\n",
    "ckckfldrs = os.listdir(\"./TensorFlow/workspace/training_demo/\")\n",
    "\n",
    "if all( i != \"images\" for i in ckckfldrs):\n",
    "    os.mkdir(\"./TensorFlow/workspace/training_demo/images\")\n",
    "    # Downloading database\n",
    "    print(\"thanks to https://public.roboflow.com/object-detection/american-sign-language-letters/1 for dataset\")\n",
    "    print(\"Downloading Dataset to ./TensorFlow/workspace/training_demo/images/...\")\n",
    "    url = 'https://public.roboflow.com/ds/wdx82NVcss?key=lyVASY8xq4'\n",
    "    path = './TensorFlow/workspace/training_demo/images/'\n",
    "    wget.download(url,out = path)\n",
    "\n",
    "    print(\"\\nUnzipping...\")\n",
    "    zipPath = os.listdir(\"./TensorFlow/workspace/training_demo/images/\")\n",
    "    zipPath = \"./TensorFlow/workspace/training_demo/images/\" + str(zipPath[0])\n",
    "    print(zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./TensorFlow/workspace/training_demo/images/\")\n",
    "\n",
    "    for item in os.listdir(\"./TensorFlow/workspace/training_demo/images/\"): # loop through items in dir\n",
    "        if item.endswith(\".zip\"): # check for \".zip\" extension\n",
    "            os.remove(\"./TensorFlow/workspace/training_demo/images/\"+ item)\n",
    "else:\n",
    "    print(\"images folder already exists\")\n",
    "\n",
    "if all( i != \"pre-trained-models\" for i in ckckfldrs):\n",
    "    os.mkdir(\"./TensorFlow/workspace/training_demo/pre-trained-models\")\n",
    "    # Downloading Pre-trained model\n",
    "    print(\"using SSD ResNet50 V1 FPN 640x640 pre-trained model from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\")\n",
    "    print(\"Downloading pre-trained model to ./TensorFlow/workspace/training_demo/pre-trained-models/..\")\n",
    "    url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "    path = './TensorFlow/workspace/training_demo/pre-trained-models/'\n",
    "    wget.download(url,out = path)\n",
    "\n",
    "    print(\"\\nUnzipping...\")\n",
    "    zipPath = os.listdir(\"./TensorFlow/workspace/training_demo/pre-trained-models/\")\n",
    "    zipPath = \"./TensorFlow/workspace/training_demo/pre-trained-models/\" + str(zipPath[0])\n",
    "    tar = tarfile.open(zipPath, \"r:gz\")\n",
    "    tar.extractall('./TensorFlow/workspace/training_demo/pre-trained-models/')\n",
    "    tar.close()\n",
    "\n",
    "    for item in os.listdir(\"./TensorFlow/workspace/training_demo/pre-trained-models/\"): # loop through items in dir\n",
    "        if item.endswith(\".tar.gz\"): # check for \".zip\" extension\n",
    "            os.remove(\"./TensorFlow/workspace/training_demo/pre-trained-models/\"+ item)\n",
    "else:\n",
    "    print(\"pre-trained-models folder already exists\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Generate .record files from labeled dataset](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records)\n",
    "(if you're using the same dataset as me, they're already generated!)  \n",
    "Something like:\n",
    "\n",
    "```bash\n",
    "# Create train data:\n",
    "python ./TensorFlow/scripts/preprocessing/generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/train -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/train.record\n",
    "\n",
    "# Create test data:\n",
    "python ./TensorFlow/scripts/preprocessing/generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/test -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/test.record\n",
    "\n",
    "# For example\n",
    "# python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/train -l C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/train.record\n",
    "# python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/test -l C:/Users/sglvladi/Documents/Tensorflow2/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/test.record\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if all( i != \"model_main_tf2.py\" for i in os.listdir(\".\")):\n",
    "    os.chdir('./TensorFlow/workspace/training_demo/') # Change the working directory\n",
    "    print(f\"working directory now: {os.getcwd()}\")\n",
    "%run -i 'model_main_tf2.py' --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config\n",
    "os.chdir('../../../')\n",
    "print(f\"working directory now: {os.getcwd()}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Monitor Training Job Progress using TensorBoard](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#tensorboard-sec)\n",
    "1. While the model trains, you can \n",
    "   1. cd into the training_demo folder\n",
    "   2. run `tensorboard --logdir=models/my_ssd_resnet50_v1_fpn` \n",
    "   3. access http://localhost:6006/ in your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Evaluating the Model](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#evaluating-the-model-optional)\n",
    "1. After the model has been trained, you can see how good it does by:\n",
    "   1. cd into the training_demo folder\n",
    "   2. run `python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config --checkpoint_dir=models/my_ssd_resnet50_v1_fpn`\n",
    "   3. access http://localhost:6006/ in your browser\n",
    "   4. seing in the images section, the eval:side_by_side images to see how good it is detecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exporting the Trained Model](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if all( i != \"exporter_main_v2.py\" for i in os.listdir(\".\")):\n",
    "    os.chdir('./TensorFlow/workspace/training_demo/') # Change the working directory\n",
    "    print(f\"working directory now: {os.getcwd()}\")\n",
    "# exports to normal model\n",
    "%run -i './exporter_main_v2.py' --input_type image_tensor --pipeline_config_path ./models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_resnet50_v1_fpn/ --output_directory ./exported-models/my_model\n",
    "# tryes to export to tflite model\n",
    "#%run -i './export_tflite_graph_tf2.py' --pipeline_config_path ./models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_resnet50_v1_fpn/ --output_directory ./exported-models/my_tflite_model\n",
    "os.chdir('../../../')\n",
    "print(f\"working directory now: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Detect Objects Using Your Webcam](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/object_detection_camera.html#detect-objects-using-your-webcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qt: Session management error: Could not open network socket\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'TensorFlow/workspace/training_demo/')\n",
    "MODELS_DIR = os.path.join(DATA_DIR, 'exported-models')\n",
    "MODEL_NAME = 'my_model_american_alphabet_sign_language'\n",
    "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
    "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "# Load label map data (for plotting)\n",
    "PATH_TO_LABELS = os.path.join(os.getcwd(), 'TensorFlow/workspace/training_demo/annotations/label_map.pbtxt')\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "\n",
    "# define the video\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# putting everything together\n",
    "import numpy as np\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret, image_np = cap.read()\n",
    "\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'][0].numpy(),\n",
    "          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "          detections['detection_scores'][0].numpy(),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=10,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    # Display output\n",
    "    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Convert a model to Lite model](https://www.tensorflow.org/lite/convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "tf.lite.OpsSet\n",
    "\n",
    "saved_model_dir = \"./TensorFlow/workspace/training_demo/exported-models/my_tflite_model/saved_model\"\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "shutil.move(\"model.tflite\", \"./TensorFlow/workspace/training_demo/converted-lite-models/\") # move converted model to the converted models folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model, it's time to create a new labelmap. Unlike standard TensorFlow, TensorFlow uses a .txt file instead of a .pbtxt file. Creating a new labelmap is actually much easier than it sounds. Let's take a look at an example. Below, I have provided the label_map.pbtxt that I used for my Pill Detection model.\n",
    "\n",
    "```txt\n",
    "item {\n",
    "    id: 1\n",
    "    name: 'Acetaminophen 325 MG Oral Tablet'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: 2\n",
    "    name: 'Ibuprofen 200 MG Oral Tablet'\n",
    "}\n",
    "```\n",
    "\n",
    "If we were to create a new labelmap for TensorFlow Lite, all we have to do is write each of the item names on it's own line like so\n",
    "\n",
    "```\n",
    "Acetaminophen 325 MG Oral Tablet\n",
    "Ibuprofen 200 MG Oral Tablet\n",
    "```\n",
    "Once you are finished filling it out save the file within the TensorFlow/workspace/training_demo/converted-lite-models/ as labels.txt. The directory should now look like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [New tutorial to try](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Try the lite model with this](https://github.com/sourcecode369/tensorflow-1/tree/master/tensorflow/lite/examples/python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [See this guide to try to convert it](https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/convert_odt_model_to_TFLite.ipynb#scrollTo=-ecGLG_Ovjcr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Export TFLite inference graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./TensorFlow/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
    "    --trained_checkpoint_dir {'./TensorFlow/workspace/training_demo/exported-models/my_model_american_alphabet_sign_language/checkpoint'} \\\n",
    "    --output_directory {'./TensorFlow/workspace/training_demo/exported-models/my_model_american_alphabet_sign_language/tflite'} \\\n",
    "    --pipeline_config_path {'./TensorFlow/workspace/training_demo/exported-models/my_model_american_alphabet_sign_language/pipeline.config'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Convert to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "_TFLITE_MODEL_PATH = \"./TensorFlow/workspace/training_demo/exported-models/my_model_american_alphabet_sign_language/model.tflite\"\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('./TensorFlow/workspace/training_demo/exported-models/my_model_american_alphabet_sign_language/tflite/saved_model')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(_TFLITE_MODEL_PATH, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the Object Detection API's labelmap into what the Task API needs:\n",
    "# a txt file with one class name on each line from index 0 to N.\n",
    "# The first '0' class indicates the background.\n",
    "# This code assumes COCO detection which has 90 classes, you can write a label\n",
    "# map file for your model if re-trained.\n",
    "_ODT_LABEL_MAP_PATH = './TensorFlow/workspace/training_demo/annotations/label_map.pbtxt'\n",
    "_TFLITE_LABEL_PATH = \"./TensorFlow/workspace/training_demo/exported-models/my_model_american_alphabet_sign_language/tflite_label_map.txt\"\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    _ODT_LABEL_MAP_PATH)\n",
    "f = open(_TFLITE_LABEL_PATH, 'w')\n",
    "for class_id in range(1, 91):\n",
    "  if class_id not in category_index:\n",
    "    f.write('???\\n')\n",
    "    continue\n",
    "  name = category_index[class_id]['name']\n",
    "  f.write(name+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "\n",
    "_TFLITE_MODEL_WITH_METADATA_PATH = \"./TensorFlow/workspace/training_demo/exported-models/my_model_american_alphabet_sign_language/model_with_metadata.tflite\"\n",
    "\n",
    "writer = object_detector.MetadataWriter.create_for_inference(\n",
    "    writer_utils.load_file(_TFLITE_MODEL_PATH), input_norm_mean=[127.5], \n",
    "    input_norm_std=[127.5], label_file_paths=[_TFLITE_LABEL_PATH])\n",
    "writer_utils.save_file(writer.populate(), _TFLITE_MODEL_WITH_METADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support import metadata\n",
    "\n",
    "displayer = metadata.MetadataDisplayer.with_model_file(_TFLITE_MODEL_WITH_METADATA_PATH)\n",
    "print(\"Metadata populated:\")\n",
    "print(displayer.get_metadata_json())\n",
    "print(\"=============================\")\n",
    "print(\"Associated file(s) populated:\")\n",
    "print(displayer.get_packed_associated_file_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Graphs with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "2022-07-08 01:08:30.065210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 01:08:30.111592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 01:08:30.111795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.9.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# conda activate signLanguageDetector\n",
    "# cd TensorFlow/workspace/training_demo/\n",
    "# tensorboard --logdir=models/my_ssd_resnet50_v1_fpn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Training the model\n",
    "1. Following [*Training Custom Object Detector*](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html) tutorial\n",
    "     - [TensorFlow Installation](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tf-install) Notes:\n",
    "       - With Anaconda installed, use `conda info --envs` to see created environments\n",
    "       - Before working on the project, do `conda activate signLanguageDetector` to activate the environment every time\n",
    "       - Install cuda and cudnn tu use GPU on manjaro with `sudo pacman -S cuda cudnn`\n",
    "       - For Object detection API, added the [TensorFlow Models repository](https://github.com/tensorflow/models) as a git submodule with the command `git submodule add https://github.com/tensorflow/models ./TensorFlow/models/`\n",
    "       - To test if everything worked out in the installation you can run `python TensorFlow/models/research/object_detection/builders/model_builder_tf2_test.py`\n",
    "      - Dataset from roboflow.com: [American Sign Language Letters Dataset](https://public.roboflow.com/object-detection/american-sign-language-letters/1)\n",
    "      - Had to do [this](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md#python-package-installation) before training to fix an error\n",
    "2. [Detect Objects Using Your Webcam](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/object_detection_camera.html#detect-objects-using-your-webcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to export with export_tflite_ssd_graph.py maybe (Maximillien)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('signLanguageDetector')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "832373f34c5392a1ac8810e042c819613272440a316383854975927ea4f31b34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
